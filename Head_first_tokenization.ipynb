{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB--HL3mIyXm",
        "outputId": "53cee1a1-a79c-4f67-bbaf-70b036618696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S4J6VHtNIyXq"
      },
      "outputs": [],
      "source": [
        "corpus=\"\"\"The quick brown fox jumps over the lazy dog.\n",
        "Hello, how are you today?\n",
        "What is the capital of France?\n",
        "The dog, which was chasing a cat, ran across the street.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cAtgyrIyXr",
        "outputId": "6026cdc3-6a9b-45b6-e324-0a89eb4f8f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumps over the lazy dog.\n",
            "Hello, how are you today?\n",
            "What is the capital of France?\n",
            "The dog, which was chasing a cat, ran across the street.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RxJ4u16IyXr",
        "outputId": "3e410ba8-df1f-4acd-c05d-8642b05c645c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "##  Tokenization\n",
        "## Sentence-->paragraphs\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bciV1X7FTM7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LKmA4Qs0IyXs"
      },
      "outputs": [],
      "source": [
        "documents=sent_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVFxh1HVIyXs",
        "outputId": "6537a71c-ef5b-4e5e-a726-b1407667a121"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "type(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKo3b2rBIyXt",
        "outputId": "2211f33b-dc9b-4adb-9fe1-3fc896d45ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumps over the lazy dog.\n",
            "Hello, how are you today?\n",
            "What is the capital of France?\n",
            "The dog, which was chasing a cat, ran across the street.\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "29rEw8qZIyXt"
      },
      "outputs": [],
      "source": [
        "## Tokenization\n",
        "## Paragraph-->words\n",
        "## sentence--->words\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvlpMfZVIyXu",
        "outputId": "7438957a-07c0-4b18-b9e5-668ea439b464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " '.',\n",
              " 'Hello',\n",
              " ',',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'today',\n",
              " '?',\n",
              " 'What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'France',\n",
              " '?',\n",
              " 'The',\n",
              " 'dog',\n",
              " ',',\n",
              " 'which',\n",
              " 'was',\n",
              " 'chasing',\n",
              " 'a',\n",
              " 'cat',\n",
              " ',',\n",
              " 'ran',\n",
              " 'across',\n",
              " 'the',\n",
              " 'street',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "word_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1yKV3sJIyXu",
        "outputId": "63d54b07-54b8-4b73-a7e8-d59c9064afc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "['Hello', ',', 'how', 'are', 'you', 'today', '?']\n",
            "['What', 'is', 'the', 'capital', 'of', 'France', '?']\n",
            "['The', 'dog', ',', 'which', 'was', 'chasing', 'a', 'cat', ',', 'ran', 'across', 'the', 'street', '.']\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "joP1Vi_EIyXu"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gVqXnjUIyXu",
        "outputId": "335bb5df-d985-4b3d-de0d-acf5dc263444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " '.',\n",
              " 'Hello',\n",
              " ',',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'today',\n",
              " '?',\n",
              " 'What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'France',\n",
              " '?',\n",
              " 'The',\n",
              " 'dog',\n",
              " ',',\n",
              " 'which',\n",
              " 'was',\n",
              " 'chasing',\n",
              " 'a',\n",
              " 'cat',\n",
              " ',',\n",
              " 'ran',\n",
              " 'across',\n",
              " 'the',\n",
              " 'street',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "wordpunct_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "X6RHfwLNIyXv"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1w5ZGk8GIyXv"
      },
      "outputs": [],
      "source": [
        "tokenizer=TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvtveuqAIyXv",
        "outputId": "077994dd-ebbf-4e16-f615-44d76bc72eb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog.',\n",
              " 'Hello',\n",
              " ',',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'today',\n",
              " '?',\n",
              " 'What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'France',\n",
              " '?',\n",
              " 'The',\n",
              " 'dog',\n",
              " ',',\n",
              " 'which',\n",
              " 'was',\n",
              " 'chasing',\n",
              " 'a',\n",
              " 'cat',\n",
              " ',',\n",
              " 'ran',\n",
              " 'across',\n",
              " 'the',\n",
              " 'street',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tokenizer.tokenize(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TreebankWordTokenizer and wordpunct_tokenize functions in NLTK differ in how they handle periods (dots). TreebankWordTokenizer includes the dot within the same word, while wordpunct_tokenize treats it as a separate word. However, TreebankWordTokenizer will also include the final dot if it's followed by a newline character."
      ],
      "metadata": {
        "id": "id5VqX1pVZjy"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}